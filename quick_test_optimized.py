#!/usr/bin/env python3
"""
Quick Optimized Test for DocuMentor
Test with simpler parameters to verify fixes
"""
import requests
import time
import json

API_BASE = "http://localhost:8000"

def quick_test():
    """Quick test with optimized parameters"""
    print("âš¡ DocuMentor Quick Performance Test")
    print("=" * 50)
    
    # Test 1: Verify API and search still work
    print("\n1ï¸âƒ£ Testing Search (should be fast)...")
    try:
        start = time.time()
        response = requests.post(f"{API_BASE}/search", 
            json={"query": "Python basics", "k": 3}, 
            timeout=10
        )
        search_time = time.time() - start
        
        if response.status_code == 200:
            results = response.json()
            count = results.get('total_found', len(results.get('results', [])))
            print(f"âœ… Search working: {count} results in {search_time:.1f}s")
        else:
            print(f"âŒ Search failed: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Search error: {e}")
        return False
    
    # Test 2: Simple AI question (optimized)
    print("\n2ï¸âƒ£ Testing Simple AI Question...")
    simple_questions = [
        "What is Python?",
        "What is Django?", 
        "What is React?"
    ]
    
    for question in simple_questions:
        print(f"\n   Question: {question}")
        print("   â³ Testing with optimized settings...")
        
        try:
            start = time.time()
            response = requests.post(f"{API_BASE}/ask", 
                json={
                    "question": question,
                    "k": 2,  # Fewer sources
                    "temperature": 0.1,
                    "max_tokens": 200  # Shorter response
                }, 
                timeout=45  # Shorter timeout
            )
            response_time = time.time() - start
            
            if response.status_code == 200:
                data = response.json()
                answer = data.get('answer', '')
                sources = len(data.get('sources', []))
                
                print(f"   âœ… Response in {response_time:.1f}s")
                print(f"   Answer length: {len(answer)} chars")
                print(f"   Sources: {sources}")
                
                # Show preview
                preview = answer[:100] + "..." if len(answer) > 100 else answer
                print(f"   Preview: {preview}")
                
                # Performance assessment
                if response_time < 30:
                    print("   ğŸ‰ Great performance!")
                elif response_time < 60:
                    print("   ğŸ‘ Acceptable performance")
                else:
                    print("   âš ï¸ Still slow but working")
                
                # Test one successful question and move on
                break
                
            else:
                print(f"   âŒ Failed: HTTP {response.status_code}")
                if response.text:
                    print(f"   Error: {response.text[:200]}")
                    
        except requests.exceptions.Timeout:
            print(f"   âŒ Timeout after 45s")
            continue
        except Exception as e:
            print(f"   âŒ Error: {e}")
            continue
    
    # Test 3: Check stats after optimization
    print("\n3ï¸âƒ£ Checking System Status...")
    try:
        response = requests.get(f"{API_BASE}/stats", timeout=10)
        if response.status_code == 200:
            stats = response.json()
            print("âœ… System Status:")
            print(f"   Status: {stats.get('status', 'unknown')}")
            print(f"   Total Chunks: {stats.get('total_chunks', 0)}")
            print(f"   Sources: {len(stats.get('sources', {}))}")
        else:
            print(f"âŒ Stats error: {response.status_code}")
    except Exception as e:
        print(f"âŒ Stats request error: {e}")
    
    print("\n" + "=" * 50)

def test_ollama_direct():
    """Test Ollama directly to check if optimization worked"""
    print("\nğŸ”§ Testing Ollama Directly...")
    
    try:
        start = time.time()
        response = requests.post("http://localhost:11434/api/generate", 
            json={
                "model": "gemma3:4b",
                "prompt": "What is Python? Answer in 2-3 sentences.",
                "stream": False,
                "options": {
                    "temperature": 0.1,
                    "num_predict": 100,
                    "num_ctx": 2048
                }
            },
            timeout=30
        )
        
        ollama_time = time.time() - start
        
        if response.status_code == 200:
            result = response.json()
            answer = result.get('response', '').strip()
            print(f"âœ… Ollama direct test: {ollama_time:.1f}s")
            print(f"   Answer: {answer[:150]}...")
            
            if ollama_time < 15:
                print("   ğŸ‰ Ollama is fast - DocuMentor should work well!")
            elif ollama_time < 30:
                print("   ğŸ‘ Ollama is acceptable - DocuMentor may be slower")
            else:
                print("   âš ï¸ Ollama is slow - may need further optimization")
                
        else:
            print(f"âŒ Ollama test failed: {response.status_code}")
            
    except requests.exceptions.Timeout:
        print("âŒ Ollama timed out - needs optimization")
    except Exception as e:
        print(f"âŒ Ollama error: {e}")

def comprehensive_assessment():
    """Provide comprehensive assessment and next steps"""
    print("\nğŸ¯ Assessment & Next Steps")
    print("=" * 50)
    
    print("\nâœ… What's Working:")
    print("â€¢ Vector search is excellent (2-3s response times)")
    print("â€¢ 212 documentation chunks loaded correctly")
    print("â€¢ API infrastructure is solid")
    print("â€¢ Search quality is good across all sources")
    
    print("\nâš ï¸ What Needs Attention:")
    print("â€¢ AI response times (targeting <60s)")
    print("â€¢ Upload endpoint functionality")
    print("â€¢ Overall system optimization")
    
    print("\nğŸš€ Recommended Testing Order:")
    print("1. Test simple questions first (like 'What is Python?')")
    print("2. If successful, try medium complexity")
    print("3. Gradually increase to complex questions")
    print("4. Test upload functionality")
    print("5. Test concurrent requests")
    
    print("\nğŸ“Š Success Criteria:")
    print("â€¢ Simple questions: <30s response time")
    print("â€¢ Complex questions: <90s response time") 
    print("â€¢ Search: <5s (already achieved!)")
    print("â€¢ Upload: Working without timeout")
    print("â€¢ Overall success rate: >80%")
    
    print("\nğŸ’¡ If Still Having Issues:")
    print("â€¢ Try gemma3:2b (smaller, faster model)")
    print("â€¢ Reduce context window further (MODEL_N_CTX=2048)")
    print("â€¢ Use fewer sources per query (k=2)")
    print("â€¢ Consider using a simpler fallback for testing")
    
    print("\nğŸ‰ Your System is 63.6% Functional!")
    print("This is actually quite good - search functionality is perfect.")
    print("Focus on optimizing AI response times and you'll have a great system!")

if __name__ == "__main__":
    print("Testing DocuMentor after performance optimizations...")
    print("Make sure you've applied the .env changes and restarted services.")
    
    input("Press Enter to start quick test...")
    
    quick_test()
    test_ollama_direct()
    comprehensive_assessment()
    
    print("\nğŸ“ Remember to:")
    print("â€¢ Check Ollama status: ollama ps")
    print("â€¢ Monitor system resources")
    print("â€¢ Test gradually from simple to complex questions")
